{
 "cells":[
  {
   "cell_type":"markdown",
   "source":[
    "# Assignment 3 - Text Analysis\n",
    "An explanation this assignment could be found in the .pdf explanation document"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"IYM3oRYbCDihbRyREDAZR5",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"fd5DYHu04JUDGQKPsrzJ02"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "\n",
    "## Materials to review for this assignment\n",
    "<h4>From Moodle:<\/h4> \n",
    "<h5><u>Review the notebooks regarding the following python topics<\/u>:<\/h5>\n",
    "<div class=\"alert alert-info\">\n",
    "&#x2714; <b>Working with strings<\/b> (tutorial notebook)<br\/>\n",
    "&#x2714; <b>Text Analysis<\/b> (tutorial notebook)<br\/>\n",
    "&#x2714; <b>Hebrew text analysis tools (tokenizer, wordnet)<\/b> (moodle example)<br\/>\n",
    "&#x2714; <b>(brief review) All previous notebooks<\/b><br\/>\n",
    "<\/div> \n",
    "<h5><u>Review the presentations regarding the following topics<\/u>:<\/h5>\n",
    "<div class=\"alert alert-info\">\n",
    "&#x2714; <b>Text Analysis<\/b> (lecture presentation)<br\/>\n",
    "&#x2714; <b>(brief review) All other presentations<\/b><br\/>\n",
    "<\/div>"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"zj535gyJj9sDddDf28PzCY",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"0KVWXr4jdPSf3umdRWcBup"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Personal Details:"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"MHfNQO7cU7jsBSZtMc5lSo",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"c1s6Ww4tDz6QgifJLEN0Dh"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Details Student 1:\n",
    "name = \"itay marlinsky\"\n",
    "id = 208634691\n",
    "mail = 'itaymerel1212@gmail.com'\n",
    "# Details Student 2:"
   ],
   "execution_count":1,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"LUrrrDn9U2WB07h8djTqu0",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"PypUWQx4VpCe7seIAHB9Ks"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Preceding Step - import modules (packages)\n",
    "This step is necessary in order to use external modules (packages). <br\/>"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"comV7tFIllk1rp9Qmy7Qkz",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"LilyYmqvNG8TowjmN12qn2"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# --------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# --------------------------------------\n",
    "\n",
    "\n",
    "# --------------------------------------\n",
    "# ------------- visualizations:\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "# --------------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "import sklearn\n",
    "from sklearn import preprocessing, metrics, pipeline, model_selection, feature_extraction \n",
    "from sklearn import naive_bayes, linear_model, svm, neural_network, neighbors, tree\n",
    "from sklearn import decomposition, cluster\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, silhouette_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron, SGDClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "# ----------------- output and visualizations: \n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.simplefilter(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "# show several prints in one cell. This will allow us to condence every trick in one cell.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "# ---------------------------------------"
   ],
   "execution_count":2,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"jIeaRMrG6IAWwlwBi4Zd8c",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"qMybIGpCKnUzEokdkiPvMF"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "### Text analysis and String manipulation imports:"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"22hidNbjccZDvkYZcdSxPQ",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"lc6FFIYYpJDt2GsG97KTDW"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# --------------------------------------\n",
    "# --------- Text analysis and Hebrew text analysis imports:\n",
    "# vectorizers:\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# regular expressions:\n",
    "import re\n",
    "# --------------------------------------"
   ],
   "execution_count":3,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"4Xk89RiMqNTlrZAYYKnOtT",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"tbGT9Yos5SeqxIaX5rc7WQ"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "### (optional) Hebrew text analysis - WordNet (for Hebrew)\n",
    "Note: the WordNet is not a must"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"9SwTdWXSdQWkhJhUebEn2f",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"uAvc4mU0HrlOpm21ihaQOz"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "#### (optional) Only if you didn't install Wordnet (for Hebrew) use:"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"StDH4zNsbLbaAlyCuxJj1K",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"JGA8AUfUtF0cOQn036tafE"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# word net installation:\n",
    "\n",
    "# unmark if you want to use and need to install\n",
    "!pip install wn\n",
    "!python -m wn download omw-he:1.4"
   ],
   "execution_count":4,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Collecting wn\r\n",
      "  Downloading wn-0.9.4-py3-none-any.whl (75 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0\/75.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7\/75.7 kB\u001b[0m \u001b[31m11.7 MB\/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: requests in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from wn) (2.30.0)\r\n",
      "Collecting tomli (from wn)\r\n",
      "  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests->wn) (3.2.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests->wn) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests->wn) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests->wn) (2023.7.22)\r\n",
      "Installing collected packages: tomli, wn\r\n",
      "Successfully installed tomli-2.0.1 wn-0.9.4\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n",
      "\r\u001b[K\rDownload (0 bytes) Requesting\r\u001b[K\rDownload [                              ] (0\/315276 bytes) Receiving\r\u001b[K\rDownload [=                             ] (8192\/315276 bytes) Receiving\r\u001b[K\rDownload [#-                            ] (16384\/315276 bytes) Receiving\r\u001b[K\rDownload [##-                           ] (24576\/315276 bytes) Receiving\r\u001b[K\rDownload [###                           ] (32768\/315276 bytes) Receiving\r\u001b[K\rDownload [###=                          ] (40960\/315276 bytes) Receiving\r\u001b[K\rDownload [####=                         ] (49152\/315276 bytes) Receiving\r\u001b[K\rDownload [#####-                        ] (57344\/315276 bytes) Receiving\r\u001b[K\rDownload [######                        ] (65536\/315276 bytes) Receiving\r\u001b[K\rDownload [#######                       ] (73728\/315276 bytes) Receiving\r\u001b[K\rDownload [#######=                      ] (81920\/315276 bytes) Receiving\r\u001b[K\rDownload [########-                     ] (90112\/315276 bytes) Receiving\r\u001b[K\rDownload [#########-                    ] (98304\/315276 bytes) Receiving\r\u001b[K\rDownload [##########                    ] (106496\/315276 bytes) Receiving\r\u001b[K\rDownload [##########=                   ] (114688\/315276 bytes) Receiving\r\u001b[K\rDownload [###########=                  ] (122880\/315276 bytes) Receiving\r\u001b[K\rDownload [############-                 ] (131072\/315276 bytes) Receiving\r\u001b[K\rDownload [#############                 ] (139264\/315276 bytes) Receiving\r\u001b[K\rDownload [##############                ] (147456\/315276 bytes) Receiving\r\u001b[K\rDownload [##############=               ] (155648\/315276 bytes) Receiving\r\u001b[K\rDownload [###############-              ] (163840\/315276 bytes) Receiving\r\u001b[K\rDownload [################-             ] (172032\/315276 bytes) Receiving\r\u001b[K\rDownload [#################             ] (180224\/315276 bytes) Receiving\r\u001b[K\rDownload [#################=            ] (188416\/315276 bytes) Receiving\r\u001b[K\rDownload [##################=           ] (196608\/315276 bytes) Receiving\r\u001b[K\rDownload [###################-          ] (204800\/315276 bytes) Receiving\r\u001b[K\rDownload [####################          ] (212992\/315276 bytes) Receiving\r\u001b[K\rDownload [#####################         ] (221184\/315276 bytes) Receiving\r\u001b[K\rDownload [#####################=        ] (229376\/315276 bytes) Receiving\r\u001b[K\rDownload [######################-       ] (237568\/315276 bytes) Receiving\r\u001b[K\rDownload [#######################-      ] (245760\/315276 bytes) Receiving\r\u001b[K\rDownload [########################      ] (253952\/315276 bytes) Receiving\r\u001b[K\rDownload [########################=     ] (262144\/315276 bytes) Receiving\r\u001b[K\rDownload [#########################=    ] (270336\/315276 bytes) Receiving\r\u001b[K\rDownload [##########################-   ] (278528\/315276 bytes) Receiving\r\u001b[K\rDownload [###########################   ] (286720\/315276 bytes) Receiving\r\u001b[K\rDownload [############################  ] (294912\/315276 bytes) Receiving\r\u001b[K\rDownload [############################= ] (303104\/315276 bytes) Receiving\r\u001b[K\rDownload [#############################-] (311296\/315276 bytes) Receiving\r\u001b[K\rDownload [##############################] (315276\/315276 bytes) Receiving\r\u001b[K\rDownload [##############################] (315276\/315276 bytes) Complete\r\n",
      "\r\u001b[KChecking \/tmp\/tmpkszf7b2m\/omw-he\/omw-he.xml\r\u001b[KReading \/tmp\/tmpkszf7b2m\/omw-he\/omw-he.xml\r\u001b[K\rRead [##########                    ] (10000\/29690) \r\u001b[K\rRead [####################          ] (20000\/29690) \r\u001b[K\rRead [##############################] (29690\/29690) \r\n",
      "\r\u001b[KUpdating lookup tables\r\u001b[K\rDatabase [                              ] (0\/29687) \r\u001b[K\rDatabase [                              ] (0\/29687) Lexicon Info\r\u001b[K\rDatabase [                              ] (0\/29687) Synsets\r\u001b[K\rDatabase [#                             ] (1000\/29687) Synsets\r\u001b[K\rDatabase [##                            ] (2000\/29687) Synsets\r\u001b[K\rDatabase [###                           ] (3000\/29687) Synsets\r\u001b[K\rDatabase [####                          ] (4000\/29687) Synsets\r\u001b[K\rDatabase [#####                         ] (5000\/29687) Synsets\r\u001b[K\rDatabase [#####-                        ] (5448\/29687) Synsets\r\u001b[K\rDatabase [#####-                        ] (5448\/29687) Words\r\u001b[K\rDatabase [######-                       ] (6448\/29687) Words\r\u001b[K\rDatabase [#######-                      ] (7448\/29687) Words\r\u001b[K\rDatabase [########-                     ] (8448\/29687) Words\r\u001b[K\rDatabase [#########-                    ] (9448\/29687) Words\r\u001b[K\rDatabase [##########-                   ] (10448\/29687) Words\r\u001b[K\rDatabase [##########=                   ] (10827\/29687) Words\r\u001b[K\rDatabase [##########=                   ] (10827\/29687) Word Forms\r\u001b[K\rDatabase [###########=                  ] (11827\/29687) Word Forms\r\u001b[K\rDatabase [############=                 ] (12827\/29687) Word Forms\r\u001b[K\rDatabase [#############=                ] (13827\/29687) Word Forms\r\u001b[K\rDatabase [##############=               ] (14827\/29687) Word Forms\r\u001b[K\rDatabase [###############=              ] (15827\/29687) Word Forms\r\u001b[K\rDatabase [################-             ] (16206\/29687) Word Forms\r\u001b[K\rDatabase [################-             ] (16206\/29687) Pronunciations\r\u001b[K\rDatabase [################-             ] (16206\/29687) Pronunciations\r\u001b[K\rDatabase [################-             ] (16206\/29687) Pronunciations\r\u001b[K\rDatabase [################-             ] (16206\/29687) Pronunciations\r\u001b[K\rDatabase [################-             ] (16206\/29687) Pronunciations\r\u001b[K\rDatabase [################-             ] (16206\/29687) Pronunciations\r\u001b[K\rDatabase [################-             ] (16206\/29687) Pronunciations\r\u001b[K\rDatabase [################-             ] (16206\/29687) Word Form Tags\r\u001b[K\rDatabase [################-             ] (16206\/29687) Word Form Tags\r\u001b[K\rDatabase [################-             ] (16206\/29687) Word Form Tags\r\u001b[K\rDatabase [################-             ] (16206\/29687) Word Form Tags\r\u001b[K\rDatabase [################-             ] (16206\/29687) Word Form Tags\r\u001b[K\rDatabase [################-             ] (16206\/29687) Word Form Tags\r\u001b[K\rDatabase [################-             ] (16206\/29687) Word Form Tags\r\u001b[K\rDatabase [################-             ] (16206\/29687) Senses\r\u001b[K\rDatabase [##################            ] (17901\/29687) Senses\r\u001b[K\rDatabase [###################-          ] (19154\/29687) Senses\r\u001b[K\rDatabase [####################-         ] (20319\/29687) Senses\r\u001b[K\rDatabase [#####################=        ] (21531\/29687) Senses\r\u001b[K\rDatabase [######################=       ] (22671\/29687) Senses\r\u001b[K\rDatabase [#######################       ] (23078\/29687) Senses\r\u001b[K\rDatabase [#######################       ] (23078\/29687) Sense Adjpositions\r\u001b[K\rDatabase [#######################       ] (23078\/29687) Counts\r\u001b[K\rDatabase [#######################       ] (23078\/29687) Counts\r\u001b[K\rDatabase [#######################       ] (23078\/29687) Syntactic Behaviours\r\u001b[K\rDatabase [#######################       ] (23078\/29687) Syntactic Behaviours\r\u001b[K\rDatabase [#######################       ] (23078\/29687) Synset Relations\r\u001b[K\rDatabase [#######################       ] (23078\/29687) Synset Relations\r\u001b[K\rDatabase [#######################       ] (23078\/29687) Synset Relations\r\u001b[K\rDatabase [#######################       ] (23078\/29687) Synset Relations\r\u001b[K\rDatabase [#######################       ] (23078\/29687) Synset Relations\r\u001b[K\rDatabase [#######################       ] (23078\/29687) Synset Relations\r\u001b[K\rDatabase [#######################       ] (23078\/29687) Synset Relations\r\u001b[K\rDatabase [#######################       ] (23078\/29687) Sense Relations\r\u001b[K\rDatabase [#######################       ] (23078\/29687) Definitions\r\u001b[K\rDatabase [########################=     ] (24503\/29687) Definitions\r\u001b[K\rDatabase [##########################    ] (25778\/29687) Definitions\r\u001b[K\rDatabase [###########################   ] (27015\/29687) Definitions\r\u001b[K\rDatabase [############################- ] (28283\/29687) Definitions\r\u001b[K\rDatabase [#############################-] (29140\/29687) Definitions\r\u001b[K\rDatabase [##############################] (29687\/29687) Definitions\r\u001b[K\rDatabase [##############################] (29687\/29687) Examples\r\u001b[K\rDatabase [##############################] (29687\/29687) Examples\r\u001b[K\rDatabase [##############################] (29687\/29687) Examples\r\u001b[K\rDatabase [##############################] (29687\/29687) Examples\r\u001b[K\rDatabase [##############################] (29687\/29687) Examples\r\u001b[K\rDatabase [##############################] (29687\/29687) Examples\r\u001b[K\rDatabase [##############################] (29687\/29687) Examples\r\u001b[K\rDatabase [##############################] (29687\/29687) Examples\r\u001b[K\rDatabase [##############################] (29687\/29687) Examples\r\u001b[K\rDatabase [##############################] (29687\/29687) Examples\r\u001b[K\rDatabase [##############################] (29687\/29687) Examples\r\u001b[K\rDatabase [##############################] (29687\/29687) Examples\r\u001b[K\rDatabase [##############################] (29687\/29687) Examples\r\u001b[K\rDatabase [##############################] (29687\/29687) Examples\r\u001b[K\rDatabase [##############################] (29687\/29687) Examples\r\u001b[K\rDatabase [##############################] (29687\/29687) \r\u001b[KAdded omw-he:1.4 (Hebrew Wordnet)\r\n",
      "\r\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"ZCccvPP9XrFLDr67QgGWuf",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"JWZXPiwa7NVRlbFuAxTxDg"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# word net import:\n",
    "\n",
    "# unmark if you want to use:\n",
    "import wn"
   ],
   "execution_count":5,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"oZzgu5AT0JcTOChVlW4Ck9",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"MjCfpwHcsxrjiCpsyuCUVA"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "### (optional) Hebrew text analysis - hebrew_tokenizer (Tokenizer for Hebrew)\n",
    "Note: the hebrew_tokenizer is not a must"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"h8Z9t2kTXGBiMiXeSGsJQE",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"1RVE2605Y6sRiFNU3TFkhn"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "#### (optional) Only if you didn't install hebrew_tokenizer use:"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"ectSq5BzGV0vKnPqd2bx8S",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"LFFD4FgtIsEsR1gbpT75Ex"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Hebrew tokenizer installation:\n",
    "\n",
    "# unmark if you want to use and need to install:\n",
    "# !pip install hebrew_tokenizer"
   ],
   "execution_count":6,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"FWAtuW28ezTL624A5VCQPD",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"DDaByWNG85iux0UNawdGjD"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Hebrew tokenizer import:\n",
    "\n",
    "# unmark if you want to use:\n",
    "# import hebrew_tokenizer as ht"
   ],
   "execution_count":7,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"hUQRiYrSvDNP2kfERwJrZp",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"kpP7lTAosmrwfifbV5EtEl"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "### Reading input files\n",
    "Reading input files for train annotated corpus (raw text data) corpus and for the test corpus"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"o70R7DrGFZ4orI2zJYPKrh",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"2MXB0K9Ade9N6fTyXe6nyz"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "train_filename = 'annotated_corpus_for_train.csv'\n",
    "test_filename  = 'corpus_for_test.csv'\n",
    "df_train = pd.read_csv(train_filename, index_col=None, encoding='utf-8')\n",
    "df_test  = pd.read_csv(test_filename, index_col=None, encoding='utf-8')"
   ],
   "execution_count":8,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"sipshWp7VYIvw9VXr8sLNi",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"cCLpxWCfp3dVDCdG8gUnl7"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "df_train.head(8)\n",
    "df_train.shape"
   ],
   "execution_count":26,
   "outputs":[
    {
     "data":{
      "text\/html":[
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "<\/style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th><\/th>\n",
       "      <th>story<\/th>\n",
       "      <th>gender<\/th>\n",
       "    <\/tr>\n",
       "  <\/thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0<\/th>\n",
       "      <td>כשחבר הזמין אותי לחול, לא באמת חשבתי שזה יקרה,...<\/td>\n",
       "      <td>0<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>1<\/th>\n",
       "      <td>לפני שהתגייסתי לצבא עשיתי כל מני מיונים ליחידו...<\/td>\n",
       "      <td>0<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>2<\/th>\n",
       "      <td>מאז שהתחילו הלימודים חלומו של כל סטודנט זה הפנ...<\/td>\n",
       "      <td>1<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>3<\/th>\n",
       "      <td>כשהייתי ילד, מטוסים היה הדבר שהכי ריתק אותי. ב...<\/td>\n",
       "      <td>0<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>4<\/th>\n",
       "      <td>‏הייתי מדריכה בכפר נוער ומתאם הכפר היינו צריכי...<\/td>\n",
       "      <td>1<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>5<\/th>\n",
       "      <td>לפני כ3 חודשים טסתי לרומא למשך שבוע. טסתי במטו...<\/td>\n",
       "      <td>1<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>6<\/th>\n",
       "      <td>אני כבר שנתיים נשוי והשנה אני ואישתי סוף סוף י...<\/td>\n",
       "      <td>0<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>7<\/th>\n",
       "      <td>השנה התחלנו שיפוץ בדירה שלנו בתל אביב. הדירה ה...<\/td>\n",
       "      <td>1<\/td>\n",
       "    <\/tr>\n",
       "  <\/tbody>\n",
       "<\/table>\n",
       "<\/div>"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    },
    {
     "data":{
      "text\/plain":[
       "(753, 2)"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"BUNBqZwA2c2mtmwD8vkAKh",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"3xPreeFmnQOz0dHX40ukeA"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "df_test.head(10)\n",
    "df_test.shape"
   ],
   "execution_count":25,
   "outputs":[
    {
     "data":{
      "text\/html":[
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "<\/style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th><\/th>\n",
       "      <th>test_example_id<\/th>\n",
       "      <th>story<\/th>\n",
       "    <\/tr>\n",
       "  <\/thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0<\/th>\n",
       "      <td>0<\/td>\n",
       "      <td>כל קיץ אני והמשפחה נוסעים לארצות הברית לוס אנג...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>1<\/th>\n",
       "      <td>1<\/td>\n",
       "      <td>הגעתי לשירות המדינה אחרי שנתיים כפעיל בתנועת \"...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>2<\/th>\n",
       "      <td>2<\/td>\n",
       "      <td>אחת האהבות הגדולות שלי אלו הכלבים שלי ושל אישת...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>3<\/th>\n",
       "      <td>3<\/td>\n",
       "      <td>רגע הגיוס לצבא היה הרגע הכי משמעותי עבורי, אני...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>4<\/th>\n",
       "      <td>4<\/td>\n",
       "      <td>אני הגעתי לברזיל ישר מקולומביה וגם אני עשיתי ע...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>5<\/th>\n",
       "      <td>5<\/td>\n",
       "      <td>בפעם האחרונה שהייתי מחוץ לארץ ישראל הייתי באפר...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>6<\/th>\n",
       "      <td>6<\/td>\n",
       "      <td>בשנת 2018 קיבלתי החלטה שאני מתחיל ללמוד לתואר ...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>7<\/th>\n",
       "      <td>7<\/td>\n",
       "      <td>בנובמבר האחרון הייתי עם חברים בטיול ים אל ים, ...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>8<\/th>\n",
       "      <td>8<\/td>\n",
       "      <td>לפני מספר חודשים, ביום שמש בהיר, קמתי בבוקר למ...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>9<\/th>\n",
       "      <td>9<\/td>\n",
       "      <td>אני לא בן אדם שנוטה לשתף בחייו האישיים, אבל או...<\/td>\n",
       "    <\/tr>\n",
       "  <\/tbody>\n",
       "<\/table>\n",
       "<\/div>"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    },
    {
     "data":{
      "text\/plain":[
       "(323, 2)"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"eg5sbiwQiShccuCNdgLXZV",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"UeZRpsRjI8YrQUhG5hq6pS"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "### Your implementation:\n",
    "Write your code solution in the following code-cells"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"Fx1pfbWXTDvzC77vYCEYCt",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"2OrFjlUyNE7rFTJicr1sV5"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# YOUR CODE HERE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "gender_map = {'m': 0, 'f': 1}\n",
    "df_train['gender'] = df_train['gender'].map(gender_map)\n",
    "\n"
   ],
   "execution_count":11,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"GTDhSB4514oxmQUcrW6pQQ",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"qRcNADxieuw03ASGMBdEsM"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "\n",
    "\n",
    "vec = TfidfVectorizer( encoding='utf-8', decode_error='strict', strip_accents=None, lowercase=True, \n",
    "                       analyzer='word',  max_features=None \n",
    "                      , norm='l2')\n",
    "\n",
    "\n",
    "sample1 = df_test['story'][0:5]\n",
    "sample2 = df_test['story'][-6:-1]\n",
    "\n",
    "\n",
    "# Transform the train and test data\n",
    "X_train = vec.fit_transform(df_train['story'])\n",
    "X_test = vec.transform(df_test['story'][5:-5])\n",
    "\n",
    "#normalization\n",
    "X_train = preprocessing.normalize(X_train)\n",
    "X_test = preprocessing.normalize(X_test)\n",
    "# Encoding gender labels\n",
    "y_train = df_train['gender']\n",
    "\n",
    "\n",
    "#load model\n",
    "clf = MultinomialNB()\n",
    "model = LogisticRegression()\n",
    "decisionTree = tree.DecisionTreeClassifier(max_depth=20, min_samples_split=11)\n",
    "\n",
    "#cross_validation\n",
    "df_predicted = cross_val_score(decisionTree, X_train, y_train, cv=10,scoring='f1_macro')\n",
    "\n",
    "average_f1 = df_predicted.mean()\n",
    "\n",
    "print(\"Average F1 Score:\", average_f1)\n",
    "\n",
    "for x in df_predicted:\n",
    "   print(\"test result: \" ,x)\n",
    "\n",
    "\n"
   ],
   "execution_count":35,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Average F1 Score: 0.5962458011824185\n",
      "test result:  0.5935828877005348\n",
      "test result:  0.5745134630765129\n",
      "test result:  0.6059907834101382\n",
      "test result:  0.5714285714285714\n",
      "test result:  0.5608899297423887\n",
      "test result:  0.5833333333333334\n",
      "test result:  0.5730550284629982\n",
      "test result:  0.49599999999999994\n",
      "test result:  0.6950393060449988\n",
      "test result:  0.7086247086247086\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"pn1MBGDhi4hSzZFEXq4pvz",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "df_predicted = pd.DataFrame()\n",
    "df_predicted['test_example_id'] = df_test['test_example_id'][5:-5]\n",
    "decisionTree = tree.DecisionTreeClassifier(max_depth=20, min_samples_split=11)\n",
    "decisionTree = decisionTree.fit(X_train,y_train)\n",
    "df_predicted['predicted_category'] = decisionTree.predict(X_test)\n",
    "print(df_predicted)"
   ],
   "execution_count":39,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "     test_example_id  predicted_category\n",
      "5                  5                   0\n",
      "6                  6                   0\n",
      "7                  7                   0\n",
      "8                  8                   0\n",
      "9                  9                   0\n",
      "..               ...                 ...\n",
      "313              313                   0\n",
      "314              314                   1\n",
      "315              315                   0\n",
      "316              316                   0\n",
      "317              317                   1\n",
      "\n",
      "[313 rows x 2 columns]\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"k6KJgGt1GAuM6GW8dTJWfK",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "X1 = vec.transform(sample1) \n",
    "X2 = vec.transform(sample2)\n",
    "\n",
    "decisionTree = tree.DecisionTreeClassifier(max_depth=20, min_samples_split=11)\n",
    "decisionTree = decisionTree.fit(X_train,y_train)\n",
    "# Predict the gender of the first sample sentence.\n",
    "predicted_gender = decisionTree.predict(X1)\n",
    "print(\"The predicted gender of the first sample sentence is:\", predicted_gender)\n",
    "\n",
    "predicted_gender = decisionTree.predict(X2)\n",
    "print(\"The predicted gender of the second sample sentence is:\", predicted_gender)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count":38,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "The predicted gender of the first sample sentence is: [1 0 0 0 1]\n",
      "The predicted gender of the second sample sentence is: [1 0 0 1 0]\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"dSRkAEPumys83t1jN8QQW2",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"A4WUpw5TaHLCbw0uguqblG"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"HFG0yCgFlnNWlJvpUvvCss",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"A4WUpw5TaHLCbw0uguqblG"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"H0QtV06aRZmZjJFfwx6x9Z",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"A4WUpw5TaHLCbw0uguqblG"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"7DQEInuAIbVWm0IHCaPNbA",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"A4WUpw5TaHLCbw0uguqblG"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"AG6pid4dfwSJrW3gIU9bug",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"A4WUpw5TaHLCbw0uguqblG"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"WAJBusQJD4Jqcs84VQWFjR",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"A4WUpw5TaHLCbw0uguqblG"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"eYUQOxBori9SrVWRibtXq3",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"A4WUpw5TaHLCbw0uguqblG"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "### Save output to csv (optional)\n",
    "After you're done save your output to the 'classification_results.csv' csv file.<br\/>\n",
    "We assume that the dataframe with your results contain the following columns:\n",
    "* column 1 (left column): 'test_example_id'  - the same id associated to each of the test stories to be predicted.\n",
    "* column 2 (right column): 'predicted_category' - the predicted gender value for each of the associated story. \n",
    "\n",
    "Assuming your predicted values are in the `df_predicted` dataframe, you should save you're results as following:"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"yjcl0LHUPaqjlavi8qTPwp",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"ebiew2nNqQaRAxI8cfxc3K"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "df_predicted.to_csv('classification_results.csv',index=False)"
   ],
   "execution_count":40,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"T7rEHMIKyHwlEEh9iSublq",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"z5ugMSTKrA9ABGEuyy7i4y"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"rotdW9nngmPbT4J9RNz8DK",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  }
 ],
 "metadata":{
  "kernelspec":{
   "display_name":"Python",
   "language":"python",
   "name":"python"
  },
  "datalore":{
   "computation_mode":"JUPYTER",
   "package_manager":"pip",
   "base_environment":"default",
   "packages":[
    {
     "name":"hebrew-tokenizer",
     "source":"PIP"
    }
   ],
   "report_row_ids":[
    "fd5DYHu04JUDGQKPsrzJ02",
    "0KVWXr4jdPSf3umdRWcBup",
    "c1s6Ww4tDz6QgifJLEN0Dh",
    "PypUWQx4VpCe7seIAHB9Ks",
    "LilyYmqvNG8TowjmN12qn2",
    "qMybIGpCKnUzEokdkiPvMF",
    "lc6FFIYYpJDt2GsG97KTDW",
    "tbGT9Yos5SeqxIaX5rc7WQ",
    "uAvc4mU0HrlOpm21ihaQOz",
    "JGA8AUfUtF0cOQn036tafE",
    "JWZXPiwa7NVRlbFuAxTxDg",
    "MjCfpwHcsxrjiCpsyuCUVA",
    "1RVE2605Y6sRiFNU3TFkhn",
    "LFFD4FgtIsEsR1gbpT75Ex",
    "DDaByWNG85iux0UNawdGjD",
    "kpP7lTAosmrwfifbV5EtEl",
    "2MXB0K9Ade9N6fTyXe6nyz",
    "cCLpxWCfp3dVDCdG8gUnl7",
    "3xPreeFmnQOz0dHX40ukeA",
    "UeZRpsRjI8YrQUhG5hq6pS",
    "2OrFjlUyNE7rFTJicr1sV5",
    "qRcNADxieuw03ASGMBdEsM",
    "l9iFkitrZ8zTqOBbJ3jmFK",
    "BXfMJN7XNk6JfY7Xe5McPa",
    "tsRUmgGUGO8FkWKZbwWD9p",
    "ebiew2nNqQaRAxI8cfxc3K",
    "z5ugMSTKrA9ABGEuyy7i4y"
   ],
   "version":3
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}